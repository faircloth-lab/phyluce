#!/usr/bin/env python
# encoding: utf-8

"""
get_fastas_from_match_counts.py

Created by Brant Faircloth on 04 June 2011.
Copyright 2011 Brant C. Faircloth. All rights reserved.
"""

import os
import re
import sqlite3
import argparse
import ConfigParser
from collections import defaultdict
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from phyluce.helpers import FullPaths, is_dir, is_file, get_names_from_config, get_contig_header_string
from phyluce.pth import get_user_param
from phyluce.log import setup_logging

#import pdb


def get_args():
    parser = argparse.ArgumentParser(
        description="Given an input SQL database of UCE locus matches, a config file " +
        "containing the loci in your data matrix, and the contigs you have assembled, extract the fastas for each " +
        "locus for each taxon in the assembled contigs, and rename those to the appropriate UCE loci, outputting " +
        "the results as a single monolithic FASTA file containing all records. " +
        "Can also incorporate data from genome-enabled taxa or other studies using the --extend-db and --extend-contigs " +
        "parameters.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--contigs',
        required=True,
        action=FullPaths,
        type=is_dir,
        help='The directory containing the assembled contigs in which you searched for UCE loci.',
    )
    parser.add_argument(
        '--locus-db',
        required=True,
        action=FullPaths,
        type=is_file,
        help='The SQL database file holding probe matches to targeted loci (usually "lastz/probe.matches.sqlite").'
    )
    parser.add_argument(
        '--match-count-output',
        required=True,
        action=FullPaths,
        type=is_file,
        help='The output file containing taxa and loci in complete/incomplete matrices generated by get_match_counts.py.'
    )
    parser.add_argument(
        '--incomplete-matrix',
        action=FullPaths,
        default=False,
        help='The path to the outfile for incomplete-matrix records.  Required when processing an incomplete data matrix.',
    )
    parser.add_argument(
        '--output',
        required=True,
        action=FullPaths,
        help='The path to the output FASTA file you want to create.'
    )
    parser.add_argument(
        "--verbosity",
        type=str,
        choices=["INFO", "WARN", "CRITICAL"],
        default="INFO",
        help="""The logging level to use."""
    )
    parser.add_argument(
        "--log-path",
        action=FullPaths,
        type=is_dir,
        default=None,
        help="""The path to a directory to hold logs."""
    )
    parser.add_argument(
        '--extend-locus-db',
        type=is_file,
        action=FullPaths,
        help='An SQLlite database file holding probe matches to other targeted loci.'
    )
    parser.add_argument(
        '--extend-locus-contigs',
        type=is_dir,
        action=FullPaths,
        help='A directory holding the assembled contigs (from genomes or another study) referenced by --extend-locus-db.'
    )
    return parser.parse_args()


def get_nodes_for_uces(c, organism, uces, extend=False, notstrict=False):
    # get only those UCEs we know are in the set
    uces = [("\'{0}\'").format(u) for u in uces]
    if not extend:
        query = "SELECT lower({0}), uce FROM match_map where uce in ({1})".format(organism, ','.join(uces))
    else:
        query = "SELECT lower({0}), uce FROM extended.match_map where uce in ({1})".format(organism, ','.join(uces))
    c.execute(query)
    rows = c.fetchall()
    node_dict = defaultdict()
    missing = []
    for node in rows:
        if node[0] is not None:
            contig_header_string = get_contig_header_string()
            match = re.search('^({})\(([+-])\)'.format(contig_header_string), node[0], flags=re.I)
            node_dict[match.groups()[0]] = (node[1], match.groups()[1])
        elif notstrict:
            missing.append(node[1])
        else:
            raise IOError("Complete matrices should have no missing data")
    return node_dict, missing


def find_file(contigs, name):
    extensions = ['.fa', '.fasta', '.contigs.fasta', '.contigs.fa', '.gz', '.fasta.gz', '.fa.gz']
    for ext in extensions:
        reads1 = os.path.join(contigs, name) + ext
        reads2 = os.path.join(contigs, name.replace('-', '_')) + ext
        for reads in [reads1, reads2]:
            if os.path.isfile(reads):
                break
            elif os.path.isfile(reads.lower()):
                reads = reads.lower()
                break
            else:
                reads = None
        if reads is not None:
            break
    if reads is None:
        raise ValueError("Cannot find the a fasta file for {} with any of the extensions ({}) ".format(
            name,
            ', '.join(extensions)
        ))
    return reads


def get_contig_name(header):
    """parse the contig name from the header of either velvet/trinity assembled contigs"""
    contig_header_string = get_contig_header_string()
    match = re.search("^({}).*".format(contig_header_string), header, flags=re.I)
    return match.groups()[0]


def replace_and_remove_bases(regex, seq, count):
    new_seq_string = str(seq.seq)
    if regex.search(new_seq_string):
        new_seq_string = re.sub(regex, "", new_seq_string)
        #print "\tReplaced < 20 ambiguous bases in {0}".format(seq.id)
        count += 1
    new_seq_string = re.sub("^[acgtn]+", "", new_seq_string)
    new_seq_string = re.sub("[acgtn]+$", "", new_seq_string)
    new_seq = Seq(new_seq_string)
    new_seq_record = SeqRecord(new_seq, id=seq.id, name='', description='')
    return new_seq_record, count


def main():
    args = get_args()
    # setup logging
    log, my_name = setup_logging(args)
    # parse the config file - allowing no values (e.g. no ":" in config file)
    config = ConfigParser.RawConfigParser(allow_no_value=True)
    config.optionxform = str
    config.read(args.match_count_output)
    # connect to the database
    conn = sqlite3.connect(args.locus_db)
    c = conn.cursor()
    # attach to external database, if passed as option
    if args.extend_locus_db:
        log.info("Attaching extended database {}".format(os.path.basename(args.extend_locus_db)))
        query = "ATTACH DATABASE '{0}' AS extended".format(args.extend_locus_db)
        c.execute(query)
    organisms = get_names_from_config(config, 'Organisms')
    log.info("There are {} taxa in the match-count-config file named {}".format(
        len(organisms),
        os.path.basename(args.match_count_output)
    ))
    uces = get_names_from_config(config, 'Loci')
    if not args.incomplete_matrix:
        log.info("There are {} shared UCE loci in a COMPLETE matrix".format(len(uces)))
    else:
        log.info("There are {} UCE loci in an INCOMPLETE matrix".format(len(uces)))
    regex = re.compile("[N,n]{1,21}")
    if args.incomplete_matrix:
        incomplete_outf = open(args.incomplete_matrix, 'w')
    with open(args.output, 'w') as uce_fasta_out:
        for organism in organisms:
            text = "Getting UCE loci for {0}".format(organism)
            log.info(text.center(65, "-"))
            written = []
            # going to need to do something more generic w/ suffixes
            name = organism.replace('_', '-')
            if args.incomplete_matrix:
                if not organism.endswith('*'):
                    reads = find_file(args.contigs, name)
                    node_dict, missing = get_nodes_for_uces(c, organism, uces, extend=False, notstrict=True)
                elif args.extend_locus_contigs:
                    # remove the asterisk
                    name = name.rstrip('*')
                    reads = find_file(args.extend_locus_contigs, name)
                    node_dict, missing = get_nodes_for_uces(c, organism.rstrip('*'), uces, extend=True, notstrict=True)
            else:
                if not name.endswith('*'):
                    reads = find_file(args.contigs, name)
                    node_dict, missing = get_nodes_for_uces(c, organism, uces)
                elif name.endswith('*') and args.extend_locus_contigs:
                    # remove the asterisk
                    name = name.rstrip('*')
                    reads = find_file(args.extend_locus_contigs, name)
                    node_dict, missing = get_nodes_for_uces(c, organism.rstrip('*'), uces, extend=True)
            count = 0
            log.info("There are {} UCE loci for {}".format(len(node_dict), organism))
            log.info("Parsing and renaming contigs for {}".format(organism))
            node_dict_set = set(node_dict.keys())
            nodes_written_set = set()
            for seq in SeqIO.parse(open(reads, 'rU'), 'fasta'):
                # break out of loop if we've already written everything we need
                # to.  this should help to keep us from iteration over thousands
                # of sequences if we do not need to.
                if nodes_written_set == node_dict_set:
                    break
                name = get_contig_name(seq.id).lower()
                if name in node_dict_set:
                    seq.id = "{0}_{1} |{0}".format(node_dict[name][0], organism.rstrip('*'))
                    seq.name = ''
                    seq.description = ''
                    # deal with strandedness because aligners sometimes dont, which
                    # is annoying
                    if node_dict[name][1] == '-':
                        seq.seq = seq.seq.reverse_complement()
                    # Replace any occurrences of <21 Ns in a given sequence with
                    # blanks.  These should gap out during alignment. Also, replace
                    # leading/trailing lowercase bases from velvet assemblies.
                    # Lowercase bases indicate low coverage, and these
                    # have been problematic in downstream alignments).
                    seq, count = replace_and_remove_bases(regex, seq, count)
                    uce_fasta_out.write(seq.format('fasta'))
                    written.append(str(node_dict[name][0]))
                    nodes_written_set.add(name)
                else:
                    pass
            if count > 0:
                log.info("Replaced <20 ambiguous bases (N) in {} contigs for {}".format(count, organism))
            if args.incomplete_matrix and missing:
                log.info("Writing missing locus information to {}".format(args.incomplete_matrix))
                incomplete_outf.write("[{0}]\n".format(organism))
                for name in missing:
                    incomplete_outf.write("{0}\n".format(name))
                    written.append(name)
            assert set(written) == set(uces), "UCE names do not match"
    text = " Completed {} ".format(my_name)
    log.info(text.center(65, "="))

if __name__ == '__main__':
    main()
