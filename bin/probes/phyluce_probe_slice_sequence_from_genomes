#!/usr/bin/env python
# encoding: utf-8
"""
File: slice_sequence_from_genomes2.py
Author: Brant Faircloth

Created by Brant Faircloth on 08 June 2013 11:06 PDT (-0700)
Copyright (c) 2013 Brant C. Faircloth. All rights reserved.

Description:

"""

import os
import re
import sys
import copy
import logging
import argparse
import configparser
from collections import defaultdict

from phyluce import lastz
from phyluce.log import setup_logging
from phyluce.helpers import FullPaths, CreateDir, is_dir, is_file

from bx.seq import twobit
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord

import pdb


def get_args():
    """Get arguments from CLI"""
    parser = argparse.ArgumentParser(
        description="""Given a LASTZ input directory, find matches, add flank, and return a FASTA file of sequences"""
    )
    parser.add_argument(
        "--conf",
        required=True,
        action=FullPaths,
        type=is_file,
        help="""Path to the configuration file""",
    )
    parser.add_argument(
        "--lastz",
        required=True,
        action=FullPaths,
        type=is_dir,
        help="""Path to the directory containing LASTZ results""",
    )
    parser.add_argument(
        "--output",
        required=True,
        action=CreateDir,
        help="""Path to the output directory for storing FASTA files""",
    )
    parser.add_argument(
        "--name-pattern",
        dest="pattern",
        type=str,
        default=None,
        help="An alternate name pattern to transform the conf entry into",
    )
    parser.add_argument(
        "--probe-prefix",
        type=str,
        default="uce-",
        help='The prefix (e.g. "uce-") added to all probes designed',
    )
    parser.add_argument(
        "--probe-regex",
        type=str,
        default="^({}\d+)(?:_p\d+.*)",
        help="The regular expression to use for matching probes",
    )
    parser.add_argument(
        "--exclude",
        type=str,
        nargs="+",
        default=None,
        help="""Species to exclude from genome slicing""",
    )
    parser.add_argument(
        "--contig_orient",
        action="store_true",
        default=False,
        help="""Check orientation by contigs versus probes - useful for multi-species probe sets""",
    )
    flank = parser.add_mutually_exclusive_group(required=True)
    flank.add_argument(
        "--flank",
        type=int,
        default=500,
        help="""The amount of flanking sequence to add to each match""",
    )
    flank.add_argument(
        "--probes",
        type=int,
        default=None,
        help="""The probe length to use""",
    )
    parser.add_argument(
        "--verbosity",
        type=str,
        choices=["INFO", "WARN", "CRITICAL"],
        default="INFO",
        help="""The logging level to use.""",
    )
    parser.add_argument(
        "--log-path",
        action=FullPaths,
        type=is_dir,
        default=None,
        help="""The path to a directory to hold logs.""",
    )
    return parser.parse_args()


def get_all_files_from_conf(conf, pattern=None):
    all_files = []
    if conf.has_section("chromos"):
        all_files.extend(conf.items("chromos"))
    if conf.has_section("scaffolds"):
        all_files.extend(conf.items("scaffolds"))
    if pattern is not None:
        files = [(v[0], pattern.format(v[0]), v[1]) for v in all_files]
    else:
        files = [(v[0], v[0], v[1]) for v in all_files]
    return files


def new_get_probe_name(header, regex):
    match = re.search(regex, header)
    return match.groups()[0]


def check_loci_for_dupes(matches):
    """Check for UCE loci that match more than one contig"""
    dupe_set = set(
        [uce for uce, contigs in list(matches.items()) if len(contigs) > 1]
    )
    return dupe_set


def slice_and_return_fasta(tb, name, min, max, flank, probes):
    if probes is None:
        if min - flank > 0:
            ss = min - flank
        else:
            ss = 0
        if max + flank < len(tb[name.encode()]):
            se = max + flank
        else:
            se = len(tb[name.encode()])
    else:
        length = abs(max - min)
        delta = probes - length
        if delta > 0:
            if delta % 2 != 0:
                delta += 1
            ss = min - delta / 2
            se = max + delta / 2
            if ss < 0:
                ss = 0
                se = se + (probes - se)
        else:
            ss = min
            se = max
    return ss, se, tb[name.encode()][int(ss) : int(se)]


def remove_ambiguous_ends(ss, se, sequence):
    start_matches = re.search("^([Nn]+)", sequence)
    end_matches = re.search("([Nn]+)$", sequence)
    if start_matches:
        new_start = len(start_matches.groups()[0])
        ss = ss + new_start
    else:
        new_start = 0
    if end_matches:
        new_end = len(end_matches.groups()[0])
        se = se - new_end
    else:
        new_end = 0
    return ss, se, sequence[new_start : len(sequence) - new_end]


def remove_repetitive_ends(ss, se, sequence):
    start_matches = re.search("^([acgt]+)", sequence)
    end_matches = re.search("([acgt]+)$", sequence)
    if start_matches:
        new_start = len(start_matches.groups()[0])
        ss = ss + new_start
    else:
        new_start = 0
    if end_matches:
        new_end = len(end_matches.groups()[0])
        se = se - new_end
    else:
        new_end = 0
    return ss, se, sequence[new_start : len(sequence) - new_end]


def build_sequence_object(
    cnt,
    contig,
    ss,
    se,
    uce,
    min,
    max,
    orient,
    sorted_positions,
    sequence,
    probes,
):
    # turn of the clipping if we're using these data for probes
    if not probes:
        ss, se, sequence = remove_ambiguous_ends(ss, se, sequence)
        ss, se, sequence = remove_repetitive_ends(ss, se, sequence)
        name_start = "Node_{0}_length_{1}_cov_1000".format(cnt, len(sequence))
    else:
        orient = list(orient)[0]
        if not orient == "+":
            orient = "revcomp"
        name_start = "slice_{}".format(cnt)
    name = "{0}|contig:{2}|slice:{3}-{4}|uce:{5}|match:{6}-{7}|orient:{8}|probes:{9}".format(
        name_start,
        len(sequence),
        contig,
        ss,
        se,
        uce,
        min,
        max,
        orient,
        len(sorted_positions),
    )
    if orient == "revcomp":
        return SeqRecord(
            Seq(sequence).reverse_complement(),
            id=name,
            name="",
            description="",
        )
    else:
        return SeqRecord(Seq(sequence), id=name, name="", description="")


def parse_lastz_file(lz, contig_orient, regex):
    all_uce_names = set()
    uce_matches = defaultdict(lambda: defaultdict(list))
    orientation = defaultdict(lambda: defaultdict(set))
    for lz in lastz.Reader(lz, long_format=True):
        # get strandedness of match
        contig_name = lz.name1
        # get name of UCE from lastz info
        uce_name = new_get_probe_name(lz.name2, regex)
        # keep a record of all UCEs matched
        all_uce_names.add(uce_name)
        uce_matches[uce_name][contig_name].append([lz.zstart1, lz.end1])
        # usually, we get orientation matches by probes. but for mixed species
        # probes, they may be in several orientations, which can cause problems,
        # so check their orientation relative to the contig
        if contig_orient:
            orientation[uce_name][contig_name].add(lz.strand1)
        else:
            orientation[uce_name][contig_name].add(lz.strand2)
    return all_uce_names, uce_matches, orientation


def main():
    args = get_args()
    # setup logging
    log, my_name = setup_logging(args)
    log.info(
        "=================== Starting Phyluce: Slice Sequence ==================="
    )
    # parse config file of genome locations (genomes in 2bit format)
    conf = configparser.ConfigParser()
    conf.optionxform = str
    try:
        assert os.path.isfile(args.conf)
    except AssertionError:
        log.critical("You need to pass the name of a config file that exists")
        sys.exit(2)
    conf.read(args.conf)
    # get the files associated with the config entries
    all_files = get_all_files_from_conf(conf, args.pattern)
    for genome in all_files:
        short_name, long_name, twobit_name = genome
        text = " Working on {} genome ".format(short_name)
        log.info(text.center(65, "-"))
        if not args.exclude or (short_name not in args.exclude):
            out_name = os.path.join(
                args.output, "{}.fasta".format(short_name.lower())
            )
            with open(out_name, "w") as outf:
                log.info("Reading {} genome".format(short_name))
                with open(twobit_name, "rb") as f:
                    tb = twobit.TwoBitFile(f)
                    # parse the lastz results of the alignment
                    lz = os.path.join(args.lastz, long_name)
                    regex = args.probe_regex.format(args.probe_prefix)
                    all_uce_names, uce_matches, orientation = parse_lastz_file(
                        lz, args.contig_orient, regex
                    )
                    # we need to check nodes for dupe matches to the same probes
                    uce_loci_matching_mult_contigs = check_loci_for_dupes(
                        uce_matches
                    )
                    # delete those loci that hit multiple probes or had multiple probes hit them
                    # this does not filter out contigs hitting multiple loci for the simple
                    # reason that many loci will hit the same "contig" in circumstances where
                    # the contig is large/chromosome sized.  These will get filtered out in
                    # the next step of the matching process after we've created fasta sequences
                    # representing each UCE locus
                    for k in list(uce_matches.keys()):
                        if k in uce_loci_matching_mult_contigs:
                            del uce_matches[k]
                    # QC contig matches
                    node_count = 0
                    orient_drop = set()
                    length_drop = set()
                    for uce_name, matches in list(uce_matches.items()):
                        bad = False
                        # make sure there is only one UCE match
                        assert (
                            len(list(matches.keys())) == 1
                        ), "There are multiple UCE matches"
                        for contig_name, positions in list(matches.items()):
                            # remove any probes with mixed orientation
                            orient = orientation[uce_name][contig_name]
                            if len(orient) > 1:
                                bad = True
                                orient_drop.add(uce_name)
                            if not bad:
                                # sort the positions for each contig
                                sorted_positions = sorted(positions)
                                if len(sorted_positions) > 1:
                                    for i in range(1, len(sorted_positions)):
                                        # drop those contigs where probes fall > 500 bp apart
                                        if (
                                            sorted_positions[i][0]
                                            - sorted_positions[i - 1][1]
                                            > 500
                                        ):
                                            bad = True
                                            length_drop.add(uce_name)
                                            break
                                        else:
                                            bad = False
                            if not bad:
                                min = sorted_positions[0][0]
                                max = sorted_positions[-1][-1]
                                ss, se, sequence = slice_and_return_fasta(
                                    tb,
                                    contig_name,
                                    min,
                                    max,
                                    args.flank,
                                    args.probes,
                                )
                                seq = build_sequence_object(
                                    node_count,
                                    contig_name,
                                    ss,
                                    se,
                                    uce_name,
                                    min,
                                    max,
                                    orient,
                                    sorted_positions,
                                    sequence,
                                    args.probes,
                                )
                                if args.probes and len(seq) < args.probes:
                                    pass
                                else:
                                    outf.write(seq.format("fasta"))
                                    node_count += 1
            output = "{}: {} uces, {} dupes, {} non-dupes, {} orient drop, {} length drop, {} written".format(
                short_name,
                len(all_uce_names),
                len(uce_loci_matching_mult_contigs),
                len(list(uce_matches.keys())),
                len(orient_drop),
                len(length_drop),
                node_count,
            )
            log.info(output)
    # end
    text = " Completed {} ".format(my_name)
    log.info(text.center(65, "="))


if __name__ == "__main__":
    main()
